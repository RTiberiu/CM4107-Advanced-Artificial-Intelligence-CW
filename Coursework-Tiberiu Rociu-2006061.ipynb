{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis on IMDb reviews using BiLSTM and ELECTRA\n",
    "Author: Tiberiu Rociu  \n",
    "Student ID: 2006061\n",
    "\n",
    "# Introduction\n",
    "\n",
    "The IMDb dataset is a collection of 50,000 movie reviews, structured as a collection of text and label pairs. The dataset is popular for binary sentiment analysis in machine learning papers (TODO INSERT REFERENCES).\n",
    "\n",
    "The task performed in this coursework is a binary sentiment classification, with the goal of predicting if a review is positive or negative, when analysing the review's textual contents that is being passed as input. As the name implies, there are only two labels for this dataset, `0` for negative, and `1` for positive.\n",
    "\n",
    "To accomplish this task, two NLP models will be used, BiLSTM and ELECTRA. An NLP model architecture is needed for this task, as the review semantics need to be understood in order to asses the sentiment behind it. Simpler machine learning models like Random Forest or Support Vector Machine won't be able to capture this nuances. \n",
    "\n",
    "# Representation Learning\n",
    "\n",
    "    TODO: Add representation plan\n",
    "\n",
    "There are two methods used in this coursework for converting the textual data into a numerical vector, each to fit the exepected format of the model they will be used on.\n",
    "\n",
    "The first method involves running the reviews through a custom pre-processing function that will remove numbers, tokenize the text using RegexpTokenizer, normalising the text, removing stopwords using Nltk, and lastly, lemmantizing the tokens using WordNetLemmatizer. The next step of the vectorization pipeline, is running the tokens through as custom FastText vectorizer, where each token is matched with a key in the FastText dictionary and replaced with the vector representation of that word. Lastly for the FastText vectorization, the tokenized vectors will be padded to ensure dimension consistency and reshaped to a 3D representation, to match with the expected model input. \n",
    "\n",
    "The second method is simpler in terms of implementation and differs from the first one, as the ELECTRA model expects the vectorization to be performed by the ElectraTokenizer. This tokenizer will perform automatically the pre-processing and vectorization, so things like manual lemmantezation or stemming are not needed, since they might clash with the word dictionary that the ELECTRA tokenizer is using. Besides the vectorized tokens, the ElectraTokenizer will also return an attention mask, to explicitly tell the model which tokens are padding and which are words, to ensure the model focuses on the important words. \n",
    "\n",
    "Both vectorization methods have the length of 250 tokens, as this encompanses the length of 90% of the reviews in the dataset. Longer reviews will have to be truncated, because accomodating for all their size would drastically increase training time. \n",
    "\n",
    "# Algorithms\n",
    "\n",
    "## BiLSTM\n",
    "\n",
    "The first model used, Bidirectional Long Short-Term Memory (BiLSTM), is a type of recurrent neural network (RNN) that improves on a unidirectional LSTM (Hochreiter and Schmidhuber, 1997), resulting in better context understanding. \n",
    "\n",
    "An RNN arhitecture allows the model to have some sort of memory, by preserving information between training loops, and allowing that information to impact the next training not just from the regular feed-forward. This still struggles with preserving information of long inputs, so the unidirectional LSTM was introduced and improved on the memory aspect by using an extra dimension in the form of the input gate, forget gate, and output gate (Siami-Namini, Tavakoli and Namin, 2019).\n",
    "\n",
    "The BiLSTM uses two LSTM models, one traversing the input data from left to right, and another LSTM model going in reverse, from right to left (Islam, 2018). This ends up caturing the context dependencies from the past and future at the same time. \n",
    "\n",
    "    TODO: ADD SOME STUFF ON THE TUNING MAYBE?\n",
    "\n",
    "## ELECTRA\n",
    "\n",
    "The second model used, Efficiently Learning an Encoder that Classifies Token Replacements Accurately (ELECTRA), is a pre-trained model that improves on the popular Masked Language Modelling (MLM) technique used by BERT (Clark et al., 2020). Instead of BERT's method, of masking certain tokens and training a model to predict what the original tokens would have been, ELECTRA uses a technique inspired by Generative Adversarial Networks (GAN) instead. These models are not in direct competition like GAN, since they are trained sequentially, and only the discriminator is retained for downstream tasks. The generator model will replace certain real tokens with tokens that would be probable in that context, and the discriminative model will attempt to identify which are the replaced tokens and which are the original from that given input. This approach outperforms other MLM methods such as BERT because the model is utilizes the entire input during training, not just the smaller subset of masked tokens. \n",
    "\n",
    "The general ELECTRA model trained on a large vocabulary, that includes Wikipedia, BooksCorpus, and other web-based datasets like CommonCrawl, can be further fine-tuned by training it on the dataset that predictions will be made on, adding this way even more domain knowledge to the model. There are many considerations for this last step of getting a custom ELECTRA model, as choosing the wrong training parameters, like training epochs, learning rate, warmup steps, and weight decay, can result in a model that overfits the data and doesn't generalize too well. \n",
    "\n",
    "\n",
    "# Evaluation\n",
    "\n",
    "    TODO: Add evaluation plan\n",
    "\n",
    "# References\n",
    "\n",
    "1. Hochreiter, S. and Schmidhuber, J. (1997) ‘Long Short-Term Memory’, Neural Computation, 9(8), pp. 1735–1780. Available at: https://doi.org/10.1162/neco.1997.9.8.1735.\n",
    "\n",
    "2. Islam, M.S. (2018) A Deep Recurrent Neural Network with BiLSTM model for Sentiment Classification. Available at: https://www.researchgate.net/publication/328333982_A_Deep_Recurrent_Neural_Network_with_BiLSTM_model_for_Sentiment_Classification.\n",
    "\n",
    "3. Siami-Namini, S., Tavakoli, N. and Namin, A.S. (2019) ‘The Performance of LSTM and BiLSTM in Forecasting Time Series’, 2019 IEEE International Conference on Big Data (Big Data), pp. 3285–3292. Available at: https://doi.org/10.1109/bigdata47090.2019.9005997.\n",
    "\n",
    "4. Clark, K., Luong, M.-T., Le, Q.V. and Manning, C.D. (2020). ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators. arXiv (Cornell University). doi:https://doi.org/10.48550/arxiv.2003.10555.\n",
    "‌\n",
    "\n",
    "‌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Importing the training and testing datasets\n",
    "dataset_splits = {'train': 'Dataset_IMDB_Sentiment/plain_text/train-00000-of-00001.parquet', 'test': 'Dataset_IMDB_Sentiment/plain_text/test-00000-of-00001.parquet'}\n",
    "imdb_train_df = pd.read_parquet(dataset_splits[\"train\"])\n",
    "imdb_test_df = pd.read_parquet(dataset_splits['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  label\n",
      "0  I rented I AM CURIOUS-YELLOW from my video sto...      0\n",
      "1  \"I Am Curious: Yellow\" is a risible and preten...      0\n",
      "2  If only to avoid making this type of film in t...      0\n",
      "3  This film was probably inspired by Godard's Ma...      0\n",
      "4  Oh, brother...after hearing about this ridicul...      0\n",
      "Row count: 25000\n"
     ]
    }
   ],
   "source": [
    "# Visualising the dataset \n",
    "print(imdb_train_df.head(5))\n",
    "print(f\"Row count: {len(imdb_train_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train dataset has 0 missing reviews and 0 missing labels.\n",
      "The test dataset has 0 missing reviews and 0 missing labels.\n",
      "\n",
      "Statistics for the train dataset:\n",
      "\tAverage review word count: 234\n",
      "\tMinimum review word count: 10\n",
      "\tMaximum review word count: 2470\n",
      "\n",
      "Statistics for the test dataset:\n",
      "\tAverage review word count: 229\n",
      "\tMinimum review word count: 4\n",
      "\tMaximum review word count: 2278\n"
     ]
    }
   ],
   "source": [
    "# Showing the amount of gaps for the train and test dataset\n",
    "missing_values_train = imdb_train_df[['text', 'label']].isnull().sum().to_dict()\n",
    "missing_values_test = imdb_test_df[['text', 'label']].isnull().sum().to_dict()\n",
    "print(f\"The train dataset has {missing_values_train['text']} missing reviews and {missing_values_train['label']} missing labels.\")\n",
    "print(f\"The test dataset has {missing_values_test['text']} missing reviews and {missing_values_test['label']} missing labels.\")\n",
    "\n",
    "# Calculate review lengths\n",
    "imdb_train_df['review_length'] = imdb_train_df['text'].apply(len)\n",
    "imdb_test_df['review_length'] = imdb_test_df['text'].apply(len)\n",
    "\n",
    "# Statistics for review lengths\n",
    "def print_dataset_basic_statistics(df, dataset_name):\n",
    "    # Caclulate the total word count for each review \n",
    "    df['review_length'] = df['text'].apply(lambda review: len(str(review).split()))\n",
    "    print(f\"\\nStatistics for the {dataset_name} dataset:\")\n",
    "    print(f\"\\tAverage review word count: {df['review_length'].mean():.0f}\")\n",
    "    print(f\"\\tMinimum review word count: {df['review_length'].min()}\")\n",
    "    print(f\"\\tMaximum review word count: {df['review_length'].max()}\")\n",
    "\n",
    "print_dataset_basic_statistics(imdb_train_df, \"train\")\n",
    "print_dataset_basic_statistics(imdb_test_df, \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Tiberiu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Tiberiu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('punkt') \n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin # This allows the custom class to work with the Pipeline\n",
    "from nltk.tokenize import word_tokenize, RegexpTokenizer # Import the tokenize package and regex tokenizer\n",
    "from nltk.corpus import stopwords # Import stopwords for stopwords removal\n",
    "from nltk.stem import SnowballStemmer, WordNetLemmatizer # Import the snowball stemmer (also known as Porter2)\n",
    "import re # Import regex\n",
    "import numpy as np\n",
    "\n",
    "class pre_process(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "      # Initialize objects for efficiency\n",
    "      self.stemmer = SnowballStemmer(\"english\")\n",
    "      self.lemmatizer = WordNetLemmatizer()\n",
    "      self.tokenizer = self.tokenizer = RegexpTokenizer(r'\\w+')\n",
    "      self.stopwords = stopwords.words(\"english\")\n",
    "      return None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self \n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "      processed_text = []\n",
    "      for text in X:\n",
    "        text = re.sub(r'\\d+', '', text)  # Remove numbers\n",
    "        token_text = self.tokenizer.tokenize(text) \n",
    "        normalised_text = [token.lower() for token in token_text if token.isalpha()]\n",
    "\n",
    "        no_stopwords_text = [token for token in normalised_text if token not in self.stopwords]\n",
    "\n",
    "        # Using lemmatization\n",
    "        processed_text.append([self.lemmatizer.lemmatize(word) for word in no_stopwords_text]) # Applying the lemmatizer\n",
    "\n",
    "      #  Return tokens as a list of words (this ensure compatibility with FastText)\n",
    "      return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# The FastText class\n",
    "class FastTextVectorizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, model_path, max_sequence_length, vector_dimension):\n",
    "        self.model_path = model_path\n",
    "        self.max_sequence_length = max_sequence_length\n",
    "        self.vector_dim = vector_dimension\n",
    "        self.word_vectors = self.load_fasttext_vectors()\n",
    "\n",
    "    def load_fasttext_vectors(self):\n",
    "        # Loading the FastText word vectors from the .vec file\n",
    "        word_vectors = {}\n",
    "        with open(self.model_path, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split()\n",
    "                word = parts[0]\n",
    "                vector = np.array(parts[1:], dtype=np.float32)\n",
    "                word_vectors[word] = vector\n",
    "        return word_vectors\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, tokens):\n",
    "        # Convert each tokenized text into a list of word vectors\n",
    "        tokenized_vectors = [\n",
    "            [\n",
    "                self.word_vectors[word] if word in self.word_vectors else np.zeros(self.vector_dim)\n",
    "                for word in token\n",
    "            ]\n",
    "            for token in tokens\n",
    "        ]\n",
    "\n",
    "        # Reshape data to 3D to make it compatible with the BiLSTM GRU model\n",
    "        # Pad sequences to ensure consistent dimensions: sequence length, vector dim\n",
    "        padded_data = pad_sequences(\n",
    "            [np.array(seq) for seq in tokenized_vectors],\n",
    "            maxlen = self.max_sequence_length,\n",
    "            dtype = 'float32',\n",
    "            padding = 'post',\n",
    "            truncating = 'post',\n",
    "        )\n",
    "\n",
    "        return np.array(padded_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an example of the pre-processed pipeline output:\n",
      "\tThe original text (as tokens): I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it's not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn't have much of a plot.\n",
      "\tThe pre-processed text: ['rented', 'curious', 'yellow', 'video', 'store', 'controversy', 'surrounded', 'first', 'released', 'also', 'heard', 'first', 'seized', 'u', 'custom', 'ever', 'tried', 'enter', 'country', 'therefore', 'fan', 'film', 'considered', 'controversial', 'really', 'see', 'br', 'br', 'plot', 'centered', 'around', 'young', 'swedish', 'drama', 'student', 'named', 'lena', 'want', 'learn', 'everything', 'life', 'particular', 'want', 'focus', 'attention', 'making', 'sort', 'documentary', 'average', 'swede', 'thought', 'certain', 'political', 'issue', 'vietnam', 'war', 'race', 'issue', 'united', 'state', 'asking', 'politician', 'ordinary', 'denizen', 'stockholm', 'opinion', 'politics', 'sex', 'drama', 'teacher', 'classmate', 'married', 'men', 'br', 'br', 'kill', 'curious', 'yellow', 'year', 'ago', 'considered', 'pornographic', 'really', 'sex', 'nudity', 'scene', 'far', 'even', 'shot', 'like', 'cheaply', 'made', 'porno', 'countryman', 'mind', 'find', 'shocking', 'reality', 'sex', 'nudity', 'major', 'staple', 'swedish', 'cinema', 'even', 'ingmar', 'bergman', 'arguably', 'answer', 'good', 'old', 'boy', 'john', 'ford', 'sex', 'scene', 'film', 'br', 'br', 'commend', 'filmmaker', 'fact', 'sex', 'shown', 'film', 'shown', 'artistic', 'purpose', 'rather', 'shock', 'people', 'make', 'money', 'shown', 'pornographic', 'theater', 'america', 'curious', 'yellow', 'good', 'film', 'anyone', 'wanting', 'study', 'meat', 'potato', 'pun', 'intended', 'swedish', 'cinema', 'really', 'film', 'much', 'plot']\n",
      "\tThe 3D reshaped data shape: (1, 250, 300)\n",
      "\tThe 3D reshaped data representation (sample): [[ 0.1991  0.0065 -0.0965 ...  0.1122 -0.0166 -0.1085]\n",
      " [-0.1178 -0.1638  0.0755 ...  0.1817  0.2032  0.2252]\n",
      " [-0.049   0.032   0.024  ... -0.04    0.1997  0.0506]\n",
      " ...\n",
      " [ 0.0092 -0.0123 -0.0336 ...  0.1672 -0.0127  0.0247]\n",
      " [-0.0075 -0.0557 -0.0249 ...  0.0717  0.0584  0.0515]\n",
      " [-0.0764  0.0451 -0.0883 ...  0.1588  0.0052 -0.0104]]\n"
     ]
    }
   ],
   "source": [
    "# Showcasing the pre processing and vectorization outputs used in the final model training pipelines\n",
    "from sklearn.pipeline import Pipeline # Adding the pipeline functionality\n",
    "\n",
    "# Showcasing the pre-process pipeline output\n",
    "pre_process_pipeline =  Pipeline([\n",
    "  ('prep', pre_process()) # Custom pre-processing method\n",
    "  ])\n",
    "\n",
    "pre_process_example = pre_process_pipeline.fit_transform(imdb_train_df['text'][:1])\n",
    "print(f\"Below is an example of the pre-processed pipeline output:\")\n",
    "print(f\"\\tThe original text (as tokens): {imdb_train_df['text'][0]}\")\n",
    "print(f\"\\tThe pre-processed text: {pre_process_example[0]}\")\n",
    "\n",
    "# Showcasing the FastText vectorization pipeline output with 3D shape data\n",
    "fast_text_pipeline = Pipeline([\n",
    "  (\"prep\", pre_process()), # Custom pre-processing method\n",
    "  (\"fast_text_vectorizer\", FastTextVectorizer(\n",
    "    model_path = \"Libraries/FastText/wiki-news-300d-1M.vec\",\n",
    "    max_sequence_length = 250\n",
    "    )), # FastText word to vector dictionary\n",
    "  ])\n",
    "\n",
    "fast_text_pipeline = fast_text_pipeline.fit_transform(imdb_train_df['text'][:1])\n",
    "print(f\"\\tThe 3D reshaped data shape: {fast_text_pipeline.shape}\")\n",
    "print(f\"\\tThe 3D reshaped data representation (sample): {fast_text_pipeline[0][:10]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of tokens: 124\n",
      "Maximum number of tokens: 1442\n",
      "Minimum number of tokens: 4\n",
      "90th percentile token length: 246\n"
     ]
    }
   ],
   "source": [
    "# Calculate the average tokens per imdb review. \n",
    "# This average will be used for the max sequence length in FastText, to avoid truncating and losing potential semantics information\n",
    "pre_process_example = pre_process_pipeline.fit_transform(imdb_train_df['text'].values)\n",
    "\n",
    "# Calculate token counts for each pre-processed text\n",
    "token_lengths = [len(tokens) for tokens in pre_process_example]\n",
    "\n",
    "# Calculate the statistics\n",
    "average_tokens = sum(token_lengths) / len(token_lengths)\n",
    "max_tokens = max(token_lengths)\n",
    "min_tokens = min(token_lengths)\n",
    "max_seq_len_90th  = int(np.percentile(token_lengths, 90))\n",
    "\n",
    "print(f\"Average number of tokens: {average_tokens:.0f}\")\n",
    "print(f\"Maximum number of tokens: {max_tokens}\")\n",
    "print(f\"Minimum number of tokens: {min_tokens}\")\n",
    "print(f\"90th percentile token length: {max_seq_len_90th}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the model wrapped in a custom Keras model to work with the Pipeline\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Bidirectional, LSTM, GRU, Dense, Dropout\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from keras import Input\n",
    "\n",
    "class BiLSTM_GRU_Model(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, input_shape, num_classes, dropout_rate):\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.model = self.build_model()\n",
    "    \n",
    "    def build_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Input(shape=self.input_shape))\n",
    "        model.add(Bidirectional(LSTM(32, return_sequences=True)))\n",
    "        model.add(GRU(16))\n",
    "        model.add(Dropout(self.dropout_rate))\n",
    "        model.add(Dense(self.num_classes, activation='sigmoid'))\n",
    "        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        return model\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.model.fit(X, y, epochs=10, batch_size=16, verbose=1)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        predictions = self.model.predict(X)\n",
    "        return (predictions > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train length: 25000\n",
      "X_train shape: (25000,)\n",
      "y_train length: 25000\n",
      "y_train shape: (25000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "max_sequence_length = 250 # This is the 90th percentile review token length score (rounded)\n",
    "vector_dimension = 300 # FastText vector dimension\n",
    "input_shape = (max_sequence_length, vector_dimension)  # Match the reshaped dimensions: max_sequence_length x vector_dimension\n",
    "\n",
    "bilstm_gru_NLP_pipeline = Pipeline([\n",
    "  (\"prep\", pre_process()), # Custom pre-processing method\n",
    "  (\"fast_text_vectorizer\", FastTextVectorizer(\n",
    "    model_path = \"Libraries/FastText/wiki-news-300d-1M.vec\",\n",
    "    max_sequence_length = max_sequence_length,\n",
    "    vector_dimension = vector_dimension\n",
    "    )), # FastText word to vector dictionary\n",
    "    (\"model\", BiLSTM_GRU_Model(input_shape=input_shape, num_classes=1, dropout_rate=0.3))  # BiLSTM GRU model\n",
    "  ])\n",
    "\n",
    "X_train = imdb_train_df['text'].values\n",
    "y_train = imdb_train_df['label'].values\n",
    "\n",
    "print(f\"X_train length: {len(X_train)}\")\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train length: {len(y_train)}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 54ms/step - accuracy: 0.5113 - loss: 0.6920\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 53ms/step - accuracy: 0.5388 - loss: 0.6816\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 53ms/step - accuracy: 0.6932 - loss: 0.5552\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 52ms/step - accuracy: 0.8733 - loss: 0.3108\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 53ms/step - accuracy: 0.8860 - loss: 0.2808\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 55ms/step - accuracy: 0.8952 - loss: 0.2637\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 53ms/step - accuracy: 0.9066 - loss: 0.2397\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 54ms/step - accuracy: 0.9154 - loss: 0.2220\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 51ms/step - accuracy: 0.9238 - loss: 0.2010\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 49ms/step - accuracy: 0.9297 - loss: 0.1858\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;prep&#x27;, pre_process()),\n",
       "                (&#x27;fast_text_vectorizer&#x27;,\n",
       "                 FastTextVectorizer(max_sequence_length=250,\n",
       "                                    model_path=&#x27;Libraries/FastText/wiki-news-300d-1M.vec&#x27;)),\n",
       "                (&#x27;model&#x27;,\n",
       "                 BiLSTM_GRU_Model(dropout_rate=0.3, input_shape=(250, 300),\n",
       "                                  num_classes=1))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">&nbsp;&nbsp;Pipeline<a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link \">i<span>Not fitted</span></span></label><div class=\"sk-toggleable__content \"><pre>Pipeline(steps=[(&#x27;prep&#x27;, pre_process()),\n",
       "                (&#x27;fast_text_vectorizer&#x27;,\n",
       "                 FastTextVectorizer(max_sequence_length=250,\n",
       "                                    model_path=&#x27;Libraries/FastText/wiki-news-300d-1M.vec&#x27;)),\n",
       "                (&#x27;model&#x27;,\n",
       "                 BiLSTM_GRU_Model(dropout_rate=0.3, input_shape=(250, 300),\n",
       "                                  num_classes=1))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">pre_process</label><div class=\"sk-toggleable__content \"><pre>pre_process()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">FastTextVectorizer</label><div class=\"sk-toggleable__content \"><pre>FastTextVectorizer(max_sequence_length=250,\n",
       "                   model_path=&#x27;Libraries/FastText/wiki-news-300d-1M.vec&#x27;)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">BiLSTM_GRU_Model</label><div class=\"sk-toggleable__content \"><pre>BiLSTM_GRU_Model(dropout_rate=0.3, input_shape=(250, 300), num_classes=1)</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('prep', pre_process()),\n",
       "                ('fast_text_vectorizer',\n",
       "                 FastTextVectorizer(max_sequence_length=250,\n",
       "                                    model_path='Libraries/FastText/wiki-news-300d-1M.vec')),\n",
       "                ('model',\n",
       "                 BiLSTM_GRU_Model(dropout_rate=0.3, input_shape=(250, 300),\n",
       "                                  num_classes=1))])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the pipeline\n",
    "bilstm_gru_NLP_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 22ms/step\n",
      "Predictions: [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [0]\n",
      " [1]]\n",
      "Accuracy: 0.89\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.90      0.89     12500\n",
      "           1       0.90      0.87      0.89     12500\n",
      "\n",
      "    accuracy                           0.89     25000\n",
      "   macro avg       0.89      0.89      0.89     25000\n",
      "weighted avg       0.89      0.89      0.89     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using the BiLSTM pipeline to make the predictions\n",
    "X_test = imdb_test_df['text'].values\n",
    "y_pred = bilstm_gru_NLP_pipeline.predict(X_test)\n",
    "y_test = imdb_test_df['label'].values\n",
    "print(\"Predictions:\", y_pred)\n",
    "\n",
    "# Comparing the predictions with the actual values\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING THE 2ND PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import ElectraTokenizer, ElectraForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "# Transforming into HuggingFace Dataset objects\n",
    "imdb_train_hf = Dataset.from_pandas(imdb_train_df[['text', 'label']])\n",
    "imdb_test_hf = Dataset.from_pandas(imdb_test_df[['text', 'label']])\n",
    "\n",
    "# Loading the Electra tokeniser to use for the Electra model\n",
    "electra_tokenizer = ElectraTokenizer.from_pretrained('google/electra-small-discriminator', do_lower_case = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Electra tokenising function\n",
    "def electra_tokenize_function(data):\n",
    "    return tokenizer(data['text'], padding = \"max_length\", truncation = True, return_attention_mask = True, max_length = 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 25000/25000 [00:44<00:00, 560.35 examples/s]\n",
      "Map: 100%|██████████| 25000/25000 [00:43<00:00, 571.64 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Tokenising the dataset\n",
    "imdb_train_hf = imdb_train_hf.map(electra_tokenize_function, batched = True)\n",
    "imdb_test_hf = imdb_test_hf.map(electra_tokenize_function, batched = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Loading the Electra model and setting the training parameters\n",
    "electra_model = ElectraForSequenceClassification.from_pretrained('google/electra-small-discriminator', num_labels=2)\n",
    "\n",
    "electra_training_arguments = TrainingArguments(\n",
    "    output_dir = './results',  \n",
    "    eval_strategy = \"epoch\", \n",
    "    learning_rate = 2e-5,  \n",
    "    per_device_train_batch_size = 32, # Making the model use the GPU for training\n",
    "    per_device_eval_batch_size = 32, \n",
    "    num_train_epochs = 7,\n",
    "    weight_decay = 0.01, \n",
    "    warmup_steps = 200,\n",
    "    logging_dir = './logs',\n",
    "    logging_steps = 500,\n",
    "    save_steps = 500,\n",
    "    do_train = True,\n",
    "    do_eval = True,\n",
    "    fp16 = True\n",
    ")\n",
    "\n",
    "electra_trainer = Trainer(\n",
    "    model = electra_model,\n",
    "    args = electra_training_arguments,\n",
    "    train_dataset = imdb_train_hf,\n",
    "    eval_dataset = imdb_test_hf,\n",
    "    processing_class = tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is CUDA available: True\n",
      "GPU Device Name: NVIDIA GeForce RTX 3080\n"
     ]
    }
   ],
   "source": [
    "# Making sure the script recognizes the GPU, to ensure the model is in fact training on it\n",
    "print(\"Is CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU Device Name:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 500/5474 [01:01<09:47,  8.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4595, 'grad_norm': 8.129602432250977, 'learning_rate': 1.8866135760333716e-05, 'epoch': 0.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 781/5474 [01:34<08:59,  8.69it/s]\n",
      " 14%|█▍        | 783/5474 [02:10<10:50:44,  8.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.22111102938652039, 'eval_runtime': 35.6266, 'eval_samples_per_second': 701.723, 'eval_steps_per_second': 21.95, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 1000/5474 [02:36<08:47,  8.48it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2467, 'grad_norm': 3.4743406772613525, 'learning_rate': 1.697004171406902e-05, 'epoch': 1.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 1500/5474 [03:35<07:48,  8.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2097, 'grad_norm': 7.339658260345459, 'learning_rate': 1.5073947667804325e-05, 'epoch': 1.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 1563/5474 [03:43<07:30,  8.69it/s]\n",
      " 29%|██▊       | 1565/5474 [04:19<9:10:34,  8.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2104008048772812, 'eval_runtime': 36.1802, 'eval_samples_per_second': 690.986, 'eval_steps_per_second': 21.614, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 2000/5474 [05:11<06:59,  8.28it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1768, 'grad_norm': 10.491612434387207, 'learning_rate': 1.3181645809632159e-05, 'epoch': 2.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 2345/5474 [05:52<05:59,  8.69it/s]\n",
      " 43%|████▎     | 2347/5474 [06:28<7:08:43,  8.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.21426326036453247, 'eval_runtime': 35.2065, 'eval_samples_per_second': 710.096, 'eval_steps_per_second': 22.212, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 2500/5474 [06:46<05:50,  8.49it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1644, 'grad_norm': 13.929616928100586, 'learning_rate': 1.1285551763367465e-05, 'epoch': 3.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 3000/5474 [07:45<04:51,  8.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.146, 'grad_norm': 10.455008506774902, 'learning_rate': 9.389457717102768e-06, 'epoch': 3.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 3127/5474 [08:00<04:53,  7.99it/s]\n",
      " 57%|█████▋    | 3129/5474 [08:37<5:32:02,  8.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.23497650027275085, 'eval_runtime': 36.3339, 'eval_samples_per_second': 688.062, 'eval_steps_per_second': 21.523, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 3500/5474 [09:23<03:57,  8.30it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1209, 'grad_norm': 7.093782424926758, 'learning_rate': 7.4933636708380746e-06, 'epoch': 4.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 3909/5474 [10:14<03:03,  8.51it/s]\n",
      " 71%|███████▏  | 3911/5474 [10:50<3:39:11,  8.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.25843173265457153, 'eval_runtime': 36.0038, 'eval_samples_per_second': 694.372, 'eval_steps_per_second': 21.72, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 4000/5474 [11:01<02:57,  8.31it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1235, 'grad_norm': 0.8267873525619507, 'learning_rate': 5.597269624573379e-06, 'epoch': 5.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 4500/5474 [12:02<02:06,  7.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1028, 'grad_norm': 10.743684768676758, 'learning_rate': 3.704967766401214e-06, 'epoch': 5.75}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 4691/5474 [12:26<01:32,  8.51it/s]\n",
      " 86%|████████▌ | 4693/5474 [13:02<1:48:32,  8.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2751871943473816, 'eval_runtime': 35.6822, 'eval_samples_per_second': 700.629, 'eval_steps_per_second': 21.916, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████▏| 5000/5474 [13:38<00:56,  8.46it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0995, 'grad_norm': 1.5822471380233765, 'learning_rate': 1.808873720136519e-06, 'epoch': 6.39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 5473/5474 [14:34<00:00,  8.70it/s]\n",
      "100%|██████████| 5474/5474 [15:10<00:00,  6.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.27479496598243713, 'eval_runtime': 35.0741, 'eval_samples_per_second': 712.777, 'eval_steps_per_second': 22.296, 'epoch': 7.0}\n",
      "{'train_runtime': 910.0772, 'train_samples_per_second': 192.291, 'train_steps_per_second': 6.015, 'train_loss': 0.17694938082654937, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5474, training_loss=0.17694938082654937, metrics={'train_runtime': 910.0772, 'train_samples_per_second': 192.291, 'train_steps_per_second': 6.015, 'total_flos': 5148437145600000.0, 'train_loss': 0.17694938082654937, 'epoch': 7.0})"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Electra model to fine tune it to the IMDB dataset\n",
    "# NOTE FOR MARKING PURPOSES: Below this code block there will be code that will load the trained model already.\n",
    "# Retraining the model will probably take a long time if a dedicated GPU is not used.\n",
    "electra_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./electra_custom_trained_model\\\\tokenizer_config.json',\n",
       " './electra_custom_trained_model\\\\special_tokens_map.json',\n",
       " './electra_custom_trained_model\\\\vocab.txt',\n",
       " './electra_custom_trained_model\\\\added_tokens.json')"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving the Electra model\n",
    "electra_model.save_pretrained('./electra_custom_trained_model')\n",
    "electra_tokenizer.save_pretrained('./electra_custom_trained_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the custom Electra model and tokenizer\n",
    "electra_custom_model = ElectraForSequenceClassification.from_pretrained('./electra_custom_trained_model')\n",
    "electra_custom_tokenizer = ElectraTokenizer.from_pretrained('./electra_custom_trained_model')\n",
    "\n",
    "# Create a new Trainer instance with the custom model\n",
    "custom_electra_trainer = Trainer(\n",
    "    model = electra_custom_model,\n",
    "    processing_class = electra_custom_tokenizer,\n",
    "    args = electra_training_arguments,\n",
    "    eval_dataset = imdb_test_hf\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:17<00:00, 43.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results: {'eval_loss': 0.41617077589035034, 'eval_model_preparation_time': 0.0015, 'eval_runtime': 17.8484, 'eval_samples_per_second': 1400.686, 'eval_steps_per_second': 43.813}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test dataset\n",
    "results = custom_electra_trainer.evaluate()\n",
    "print(\"Evaluation results:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:35<00:00, 22.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Electra model accuracy on the test dataset: 92.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Generating the predictions on the test dataset\n",
    "def predict_with_trainer(trainer, dataset):\n",
    "    predictions = trainer.predict(dataset)\n",
    "    preds = predictions.predictions.argmax(axis=1)\n",
    "    return preds, predictions.label_ids\n",
    "\n",
    "predictions, labels = predict_with_trainer(custom_electra_trainer, imdb_test_hf)\n",
    "\n",
    "# Showing the model accuracy\n",
    "accuracy = accuracy_score(labels, predictions)\n",
    "print(f\"Custom Electra model accuracy on the test dataset: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.94      0.91      0.93     12500\n",
      "    Positive       0.91      0.95      0.93     12500\n",
      "\n",
      "    accuracy                           0.93     25000\n",
      "   macro avg       0.93      0.93      0.93     25000\n",
      "weighted avg       0.93      0.93      0.93     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Showing the classification report\n",
    "report = classification_report(labels, predictions, target_names=['Negative', 'Positive'])\n",
    "print(\"\\nClassification Report:\\n\", report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
